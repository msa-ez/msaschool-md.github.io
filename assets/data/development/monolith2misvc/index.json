{"hash":"8ec2d2d769250ada18e8c764b3b6b292cc183178","data":{"markdownPage":{"id":"bbc81bc90a5d7fb2058df3bfd3563e3e","title":"Kafka Retry & Dead Letter Queue (New)","description":"","path":"/development/monolith2misvc/","timeToRead":3,"content":"<h1 id=\"kafka-retry--dead-letter-queue-new\"><a href=\"#kafka-retry--dead-letter-queue-new\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>Kafka Retry &#x26; Dead Letter Queue (New)</h1>\n<h1 id=\"kafka-retry--dead-letter-queue-new-1\"><a href=\"#kafka-retry--dead-letter-queue-new-1\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>Kafka Retry &#x26; Dead Letter Queue (New)</h1>\n<h3 id=\"retry--dlq\"><a href=\"#retry--dlq\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>Retry &#x26; DLQ</h3>\n<h4 id=\"kafka-retry\"><a href=\"#kafka-retry\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>Kafka Retry</h4>\n<ul>\n<li>Consumer가 message를 처리하던 중 오류가 발생하면 해당 Message를 다시 Polling하여 처리해야 한다. </li>\n<li>이를 Retry라고 하며, 간단하게 Kafka 설정으로 동작할 수 있다. </li>\n<li>Inventory 마이크로서비스 application.yml 의 cloud.stream.bindings.event-in 하위의 설정을 주석해제하고 저장한다.</li>\n</ul>\n<pre class=\"language-sh\"><code class=\"language-sh\">bindings:\n  event-in:\n    group: product\n    destination: kafkatest\n    contentType: application/json\n    consumer:\n      max-attempts: 3\n      back-off-initial-interval: 1000\n      back-off-max-interval: 1000\n      back-off-multiplier: 1.0\n      defaultRetryable: false  </code></pre>\n<ul>\n<li>3번의 retry를 수행하는데 Retry시 백오프 초기간격이 1초, 이후 최대 1초 간격으로 retry를 실행한다. </li>\n<li>Inventory 서비스의 PolicyHandler.java에서 아래 오류 발생 코드를 주입한다: </li>\n</ul>\n<pre class=\"language-java\"><code class=\"language-java\"><span class=\"token annotation punctuation\">@StreamListener</span><span class=\"token punctuation\">(</span><span class=\"token class-name\">KafkaProcessor</span><span class=\"token punctuation\">.</span>INPUT<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">wheneverOrderPlaced_DecreaseStock</span><span class=\"token punctuation\">(</span><span class=\"token annotation punctuation\">@Payload</span> <span class=\"token class-name\">OrderPlaced</span> orderPlaced<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n\n\t\t\t<span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span>\n\t\t\t\t\n        <span class=\"token keyword\">throw</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">RuntimeException</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">//always fail</span>\n\n    <span class=\"token punctuation\">}</span></code></pre>\n<ul>\n<li>Order와 Product 마이크로서비스를 기동한다.</li>\n</ul>\n<pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token builtin class-name\">cd</span> order\nmvn spring-boot:run</code></pre>\n<pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token builtin class-name\">cd</span> inventory\nmvn spring-boot:run</code></pre>\n<ul>\n<li>재고를 등록한다</li>\n</ul>\n<pre class=\"language-text\"><code class=\"language-text\">http :8082/inventories id=1 stock=1000</code></pre>\n<ul>\n<li>Order 서비스에 포스팅하여 Kafka Event를 발행한다.</li>\n</ul>\n<pre class=\"language-text\"><code class=\"language-text\">http :8081/orders productId=1 qty=3</code></pre>\n<ul>\n<li>Inventory에서 Message를 subscribe하여 내용을 출력한다. </li>\n<li>throw new RuntimeException에 의해 Kafka retry가 수행되는지 Console의 log로 확인한다.</li>\n<li>허나, </li>\n<li>해당 메시지는 처리될 수 없으므로 파티션 Lag가 항상 잔존하게 된다.</li>\n</ul>\n<pre class=\"language-sh\"><code class=\"language-sh\">./kafka-consumer-groups --bootstrap-server localhost:9092 --group inventory --describe</code></pre>\n<ul>\n<li>이는 별도의 Topic에 저장한 후 백오피스에서 처리해야 할 대상인 것이다. </li>\n</ul>\n<h4 id=\"kafka-dead-letter-queuedlq\"><a href=\"#kafka-dead-letter-queuedlq\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>Kafka Dead Letter Queue(DLQ)</h4>\n<ul>\n<li>Kafka에서 retry를 통해서도 처리하지 못하는 message를 Posion pill이라고 한다.</li>\n<li>Kafka에서 Posion pill은 별도의 메시지 저장소인 DLQ로 보내지게 된다. </li>\n<li>DLQ는 또 하나의 topic이며 Consumer에서 정상적으로 처리되지 못한 message들이 쌓여있다. </li>\n<li>DLQ를 설정하기 위해서 아래와 같이 Inventory의 application.yml를 변경한다. </li>\n<li>cloud.stream.kafka 아래에 있는 아래 설정을 주석해제 한다. </li>\n</ul>\n<pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">bindings</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">event-in</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">consumer</span><span class=\"token punctuation\">:</span>\n      <span class=\"token key atrule\">enableDlq</span><span class=\"token punctuation\">:</span> <span class=\"token boolean important\">true</span>\n      <span class=\"token key atrule\">dlqName</span><span class=\"token punctuation\">:</span> dlq<span class=\"token punctuation\">-</span>kafkatest\n      <span class=\"token key atrule\">dlqPartitions</span><span class=\"token punctuation\">:</span> <span class=\"token number\">1</span></code></pre>\n<ul>\n<li>저장 후 Inventory 마이크로서비스를 재기동한다.</li>\n</ul>\n<blockquote>\n<p>서비스가 기동되면서 Retry를 반복하게 되고, 그래도 처리하지 못한 메시지를 DLQ로 보내는 것이 Console에 확인된다.\nSent to DLQ  a message with key='null' and payload='{123, 34, 101, 118, 101, 110, 116, 84, 121, 112, 1...' received from 0</p>\n</blockquote>\n<ul>\n<li>설정에서 지정한 DLQ 토픽이 생성되었는지 확인한다.</li>\n</ul>\n<pre class=\"language-sh\"><code class=\"language-sh\">cd kafka\ndocker-compose exec -it kafka /bin/bash\ncd /bin\n./kafka-topics --bootstrap-server http://localhost:9092  --list</code></pre>\n<h4 id=\"kafka-dlq-test\"><a href=\"#kafka-dlq-test\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>Kafka DLQ Test</h4>\n<ul>\n<li>Order 서비스에 포스팅하여 Kafka Event를 추가 발행한다.</li>\n</ul>\n<pre class=\"language-text\"><code class=\"language-text\">http POST :8081/orders productId=1 qty=1</code></pre>\n<ul>\n<li>Product에서 retry 3번 시도 후, 자동으로 DLQ로 보낸다. </li>\n<li>아래 명령어를 통해 DLQ에 해당 message가 쌓였는지 확인한다. </li>\n</ul>\n<pre class=\"language-sh\"><code class=\"language-sh\">./kafka-console-consumer --bootstrap-server http://localhost:9092 --topic dlq-kafkatest --from-beginning</code></pre>\n<ul>\n<li>커밋모드가 자동일때 Dlq에 처리되지 않은 메세지를 보낸 후, 자동으로 Offset을 증가시켜 Lag가 쌓이지 않게 된다.</li>\n</ul>\n<pre class=\"language-sh\"><code class=\"language-sh\">./kafka-consumer-groups --bootstrap-server localhost:9092 --group inventory --describe</code></pre>\n","sidebar":"business","next":"","prev":"","headings":[{"depth":1,"value":"Kafka Retry & Dead Letter Queue (New)","anchor":"#kafka-retry--dead-letter-queue-new"},{"depth":1,"value":"Kafka Retry & Dead Letter Queue (New)","anchor":"#kafka-retry--dead-letter-queue-new-1"},{"depth":3,"value":"Retry & DLQ","anchor":"#retry--dlq"},{"depth":4,"value":"Kafka Retry","anchor":"#kafka-retry"},{"depth":4,"value":"Kafka Dead Letter Queue(DLQ)","anchor":"#kafka-dead-letter-queuedlq"},{"depth":4,"value":"Kafka DLQ Test","anchor":"#kafka-dlq-test"}]},"allMarkdownPage":{"edges":[{"node":{"path":"/operations/ops-service/","title":"12번가 마이크로서비스 라우터(Service) 적용"}},{"node":{"path":"/operations/ops-utility/","title":"쿠버네티스 유틸리티"}},{"node":{"path":"/operations/ops-persistence-volume/","title":"파일시스템 (볼륨) 연결과 데이터베이스 설정"}},{"node":{"path":"/operations/ops-service-mesh-istio/","title":"[Service Mesh] Istio"}},{"node":{"path":"/operations/ops-readiness/","title":"무정지 배포 실습"}},{"node":{"path":"/operations/ops-kubernetes/","title":"Kubernetes Basic Commands"}},{"node":{"path":"/operations/ops-liveness/","title":"셀프힐링 실습"}},{"node":{"path":"/operations/ops-aws-setting/","title":"AWS Cloud Setup(EKS, ECR 설정)"}},{"node":{"path":"/operations/ops-ingress-virtualhost/","title":"Ingress - Virtual Host based"}},{"node":{"path":"/operations/ops-anatomy-kubernetes/","title":"쿠버네티스 내부구조 분석"}},{"node":{"path":"/operations/ops-ingress/","title":"Ingress 를 통한 진입점 통일 - Path-based routing"}},{"node":{"path":"/operations/ops-autoscale/","title":"Pod Auto Scaling"}},{"node":{"path":"/operations/ops-deploy-my-app/","title":"애플리케이션 패키징,도커라이징,클러스터 배포"}},{"node":{"path":"/operations/msa-logging/","title":"MSA 로깅 with EFK Stack"}},{"node":{"path":"/operations/k8s-monitoring/","title":"MSA 모니터링 with installing Grafana"}},{"node":{"path":"/operations/ops-argo-rollout-canary-istio/","title":"[GitOps] Argo Rollout 와 Istio 를 통한 카나리 배포"}},{"node":{"path":"/operations/istio-msa-telemetry/","title":"[Service Mesh] MSA 모니터링 w/ Istio addon Grafana"}},{"node":{"path":"/operations/istio-resiliency-part2/","title":"[Service Mesh] Istio 를 통한 서비스 회복성 Part2 - 서킷브레이커"}},{"node":{"path":"/operations/istio-traffic/","title":"[Service Mesh] Istio 를 통한 동적 트래픽 라우팅"}},{"node":{"path":"/operations/istio-resiliency-part1/","title":"[Service Mesh] Istio 를 통한 서비스 회복성 Part1 - 타임아웃/재시도"}},{"node":{"path":"/operations/azure/","title":"Azure Cloud Setup (AKS, ACR 설정)"}},{"node":{"path":"/operations/istio-metric-based-hpa/","title":"[Service Mesh] Istio Metrics based HPA"}},{"node":{"path":"/development/keycloak-oauth2-2/","title":"Pub/Sub 방식의 연동 (New)"}},{"node":{"path":"/operations/gitops-argo-cd/","title":"[GitOps] Argo CD 를 통한 카나리 배포"}},{"node":{"path":"/operations/end-to-end/","title":"12번가 전체 마이크로서비스의 배포"}},{"node":{"path":"/operations/apply-security/","title":"12번가 Mall에 토큰인증 적용하기"}},{"node":{"path":"/development/oauth2withkeycloak/","title":"Req/Res 방식에서 장애전파 차단 - 서킷브레이커 (New)"}},{"node":{"path":"/development/keycloak-oauth2-3/","title":"Pub/Sub 방식의 연동 - Compensation 과 Correlation (New)"}},{"node":{"path":"/development/oauth2/","title":"Req/Res 방식의 MSA 연동 (New)"}},{"node":{"path":"/development/monolith2misvc/","title":"Kafka Retry & Dead Letter Queue (New)"}},{"node":{"path":"/development/kafka-retry-dlq/","title":"Application Packaging with Container (Docker)"}},{"node":{"path":"/development/gateway/","title":"단위 마이크로 서비스의 실행 (New)"}},{"node":{"path":"/development/kafka-manual-commit/","title":"Data Projection with CQRS"}},{"node":{"path":"/development/keycloak-oauth2-1/","title":"Kafka 기본 명령어 (New)"}},{"node":{"path":"/development/kafka-scaling/","title":"Data Projection with GraphQL"}},{"node":{"path":"/development/cna-pubsub/","title":"JWT Token 기반 인증 인가 - Advanced"}},{"node":{"path":"/development/kafka-base/","title":"JWT Token 기반 인증 인가"}},{"node":{"path":"/development/cna-pubsub2/","title":"Data Projection with Frontend and HATEOAS"}},{"node":{"path":"/development/front-end/","title":"Kafka Scaling (New)"}},{"node":{"path":"/development/circuitbreaker/","title":"API Gateway"}},{"node":{"path":"/business/","title":"[분석] DDD 이벤트의 도출 - 12번가 쇼핑몰"}},{"node":{"path":"/business/eventstorming-fooddelivery/","title":"[이벤트스토밍] DDD Food Delivery 예제"}},{"node":{"path":"/development/advanced-connect/","title":"Contract Test (Consumer Driven Test)"}},{"node":{"path":"/business/ddd-google-drive/","title":"[이벤트스토밍] DDD 구글 드라이브 예제"}}]}},"context":{}}